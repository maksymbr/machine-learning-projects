\section{Formalism}
\label{formalism}

\textit{Formalism/methods: Discussion of the methods used and their basis/suitability.}


Regression: Finding a functional relationship between an input data set and a reference data set. The goal is to construct a function that maps input data to continuous output values. (Ref. Lecture notes)

\subsection{Polynomial regression}

Since obtaining these data points may not be trivial, we want to use these data to fit a function which can allow us to make predictions for values of y which are not in the present set. The perhaps simplest approach is to assume we can parametrize our function in terms of a polynomial of degree n−1 with n points, that is (\ref{} lectures)
\be{}
y(x_i) = \tilde{y}_i + \epsilon_i=\sum_{j=0}^{n-1}\beta_jx_i^j+\epsilon_i\, ,
\ee
which can be written as (\ref{} lecture slides):
\be{}
\bm{y} = \bm{X\beta} + \bm{\epsilon}\, ,
\ee
where
\be{}
\bm{y} = [y_0,y_1,...,y_{n-1}]^T, \quad \bm{\beta} = [\beta_0,\beta_1,...,\beta_{n-1}]^T, \quad \bm{\epsilon} = [\epsilon_0,\epsilon_1,...,\epsilon_{n-1}]^T\, ,
\ee
\[
\bm{X} =
  \begin{bmatrix}
    x_{00} & x_{01} & x_{02} & ... & x_{0,n-1} \\
    x_{10} & x_{11} & x_{12} & ... & x_{1,n-1} \\
    ... & ... & ... & ... & ... \\
    x_{n-1,0} & x_{n-1,1} & x_{n-1,2} & ... & x_{n-1,n-1} \\
  \end{bmatrix}
\]
The idea is to obtain an optimal set of $\beta_i$ values, which can fit best our current and future datasets. We do this by defining an approximation
\be{}
\bm{\tilde{y}}=\bm{X\beta}\, ,
\ee
and minimising the so-called \textit{cost function}
\be{}
\bm{C}(\bm{\beta}) = \frac{1}{n}\sum_{i=0}^{n-1}\left(y_i-\tilde{y}_i\right)=\frac{1}{n}\bm{\left\{\left(y-\tilde{y}\right)^T\left(y-\tilde{y}\right)\right\}}\, ,
\ee
which gives us the equations for desired parameters (\ref{} lecture notes)
\be{}
\bm{\beta} = \left(\bm{X^TX}\right)^{-1}\bm{X^Ty}\, .
\ee
Such an approach is based on the assumption that the matrix $\bm{X^TX}$ can be inverted (non-singular). This, however, is often not the case and the standard matrix inversion algorithm can often lead to singularities. One of approaches to avoid this is called \textbf{Singular Value Decomposition}, which allows us to rewrite $X$ in terms of an orthogonal/unitary transformation $U$ (\ref{} lecture notes)
\be{}
\bm{X}=\bm{U\Sigma V^T}\, ,
\ee
With this in mind, it can be shown that (\ref{} lecture notes)
\be{}
\bm{X\beta}=\bm{X}\left(\bm{VDV^T}\right)^{-1}\bm{X^Ty}=\bm{U\Sigma V^T}\left(\bm{VDV^T}\right)^{-1}\left(\bm{U\Sigma V^T}\right)^T\bm{y}=\bm{UU^Ty}\, .
\ee
Another approach is to simply add a small parameter
\be{}
\bm{X^TX}\rightarrow\bm{X^TX}+\bm{\lambda I}\, ,
\ee
which is basically what we end up with, while considering the so-called Ridge regression.

\subsection{Ridge regression}

The amount of regularization to apply during learning can be controlled by a hyper‐ parameter. A hyperparameter is a parameter of a learning algorithm (not of the model). As such, it is not affected by the learning algorithm itself; it must be set prior to training and remains constant during training. If you set the regularization hyper‐ parameter to a very large value, you will get an almost flat model (a slope close to zero); the learning algorithm will almost certainly not overfit the training data, but it will be less likely to find a good solution. Tuning hyperparameters is an important part of building a Machine Learning system (you will see a detailed example in the next chapter).

\be{}
\, ,
\ee
\be{}
\, ,
\ee
\be{}
\, ,
\ee

\subsection{LASSO regression}

For Lasso you can simply state that it optimizes the learning rate, that is it finds the optimal learning rate via various methods

https://scikit-learn.org/stable/modules/sgd.html

\subsection{Resampling Methods - Cross validation}
Cross-validation is a statistical method used to estimate the skill of machine learning models.

It is commonly used in applied machine learning to compare and select a model for a given predictive modeling problem because it is easy to understand, easy to implement, and results in skill estimates that generally have a lower bias than other methods.

Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample.

The procedure has a single parameter called k that refers to the number of groups that a given data sample is to be split into. As such, the procedure is often called k-fold cross-validation. When a specific value for k is chosen, it may be used in place of k in the reference to the model, such as k=10 becoming 10-fold cross-validation.



(from hands on machine learning)
The problem is that you measured the generalization error multiple times on the test set, and you adapted the model and hyperparameters to produce the best model for that set. This means that the model is unlikely to perform as well on new data.

A common solution to this problem is to have a second holdout set called the valida‐ tion set. You train multiple models with various hyperparameters using the training set, you select the model and hyperparameters that perform best on the validation set, and when you’re happy with your model you run a single final test against the test set to get an estimate of the generalization error.

To avoid “wasting” too much training data in validation sets, a common technique is to use cross-validation: the training set is split into complementary subsets, and each model is trained against a different combination of these subsets and validated against the remaining parts. Once the model type and hyperparameters have been selected, a final model is trained using these hyperparameters on the full training set, and the generalized error is measured on the test set. 

\textbf{Cross-validation} is primarily used in applied machine learning to estimate the skill of a machine learning model on unseen data. That is, to use a limited sample in order to estimate how the model is expected to perform in general when used to make predictions on data not used during the training of the model.

It is a popular method because it is simple to understand and because it generally results in a less biased or less optimistic estimate of the model skill than other methods, such as a simple train/test split.

The general procedure is as follows:

Shuffle the dataset randomly.
Split the dataset into k groups
For each unique group:
Take the group as a hold out or test data set
Take the remaining groups as a training data set
Fit a model on the training set and evaluate it on the test set
Retain the evaluation score and discard the model
Summarize the skill of the model using the sample of model evaluation scores



Configuration of k
The k value must be chosen carefully for your data sample.

A poorly chosen value for k may result in a mis-representative idea of the skill of the model, such as a score with a high variance (that may change a lot based on the data used to fit the model), or a high bias, (such as an overestimate of the skill of the model).

Three common tactics for choosing a value for k are as follows:

Representative: The value for k is chosen such that each train/test group of data samples is large enough to be statistically representative of the broader dataset.
k=10: The value for k is fixed to 10, a value that has been found through experimentation to generally result in a model skill estimate with low bias a modest variance.
k=n: The value for k is fixed to n, where n is the size of the dataset to give each test sample an opportunity to be used in the hold out dataset. This approach is called leave-one-out cross-validation.

\subsubsection{Bias-variance tradeoff}
Overgeneralizing is something that we humans do all too often, and unfortunately machines can fall into the same trap if we are not careful. In Machine Learning this is called overfitting: it means that the model performs well on the training data, but it does not generalize well.

Complex models such as deep neural networks can detect subtle patterns in the data, but if the training set is noisy, or if it is too small (which introduces sampling noise), then the model is likely to detect patterns in the noise itself. Obviously these patterns will not generalize to new instances. 

Constraining a model to make it simpler and reduce the risk of overfitting is called regularization.

As you might guess, underfitting is the opposite of overfitting: it occurs when your model is too simple to learn the underlying structure of the data.



Possible solutions for overfitting are to simplify the model, constrain it (i.e., regularize it), or get a lot more training data.
\be{}
\, ,
\ee
\be{}
\, ,
\ee
\be{}
\, ,
\ee
\be{}
\, ,
\ee
\be{}
\, ,
\ee
\be{}
\, ,
\ee
\be{}
\, ,
\ee
\be{}
\, ,
\ee
\be{}
\, ,
\ee




